{"version":3,"file":"llms.d.cts","names":["BasePromptValueInterface","LLMResult","Generation","GenerationChunk","BaseCallbackConfig","CallbackManagerForLLMRun","Callbacks","BaseLanguageModel","BaseLanguageModelCallOptions","BaseLanguageModelInput","BaseLanguageModelParams","RunnableConfig","BaseCache","SerializedLLM","Record","BaseLLMParams","BaseLLMCallOptions","BaseLLM","CallOptions","Exclude","Omit","Promise","AsyncGenerator","Partial","prompts","cache","llmStringKey","parsedOptions","handledOptions","runId","LLM"],"sources":["../../src/language_models/llms.d.ts"],"sourcesContent":["import type { BasePromptValueInterface } from \"../prompt_values.js\";\nimport { type LLMResult, type Generation, GenerationChunk } from \"../outputs.js\";\nimport { type BaseCallbackConfig, type CallbackManagerForLLMRun, type Callbacks } from \"../callbacks/manager.js\";\nimport { BaseLanguageModel, type BaseLanguageModelCallOptions, type BaseLanguageModelInput, type BaseLanguageModelParams } from \"./base.js\";\nimport type { RunnableConfig } from \"../runnables/config.js\";\nimport type { BaseCache } from \"../caches/base.js\";\nexport type SerializedLLM = {\n    _model: string;\n    _type: string;\n} & Record<string, any>;\nexport interface BaseLLMParams extends BaseLanguageModelParams {\n}\nexport interface BaseLLMCallOptions extends BaseLanguageModelCallOptions {\n}\n/**\n * LLM Wrapper. Takes in a prompt (or prompts) and returns a string.\n */\nexport declare abstract class BaseLLM<CallOptions extends BaseLLMCallOptions = BaseLLMCallOptions> extends BaseLanguageModel<string, CallOptions> {\n    // Backwards compatibility since fields have been moved to RunnableConfig\n    ParsedCallOptions: Omit<CallOptions, Exclude<keyof RunnableConfig, \"signal\" | \"timeout\" | \"maxConcurrency\">>;\n    // Only ever instantiated in main LangChain\n    lc_namespace: string[];\n    /**\n     * This method takes an input and options, and returns a string. It\n     * converts the input to a prompt value and generates a result based on\n     * the prompt.\n     * @param input Input for the LLM.\n     * @param options Options for the LLM call.\n     * @returns A string result based on the prompt.\n     */\n    invoke(input: BaseLanguageModelInput, options?: CallOptions): Promise<string>;\n    // eslint-disable-next-line require-yield\n    _streamResponseChunks(_input: string, _options: this[\"ParsedCallOptions\"], _runManager?: CallbackManagerForLLMRun): AsyncGenerator<GenerationChunk>;\n    protected _separateRunnableConfigFromCallOptionsCompat(options?: Partial<CallOptions>): [RunnableConfig, this[\"ParsedCallOptions\"]];\n    _streamIterator(input: BaseLanguageModelInput, options?: CallOptions): AsyncGenerator<string>;\n    /**\n     * This method takes prompt values, options, and callbacks, and generates\n     * a result based on the prompts.\n     * @param promptValues Prompt values for the LLM.\n     * @param options Options for the LLM call.\n     * @param callbacks Callbacks for the LLM call.\n     * @returns An LLMResult based on the prompts.\n     */\n    generatePrompt(promptValues: BasePromptValueInterface[], options?: string[] | CallOptions, callbacks?: Callbacks): Promise<LLMResult>;\n    /**\n     * Run the LLM on the given prompts and input.\n     */\n    abstract _generate(prompts: string[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<LLMResult>;\n    /**\n     * Get the parameters used to invoke the model\n     */\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    invocationParams(_options?: this[\"ParsedCallOptions\"]): any;\n    _flattenLLMResult(llmResult: LLMResult): LLMResult[];\n    /** @ignore */\n    _generateUncached(prompts: string[], parsedOptions: this[\"ParsedCallOptions\"], handledOptions: BaseCallbackConfig, startedRunManagers?: CallbackManagerForLLMRun[]): Promise<LLMResult>;\n    _generateCached({ prompts, cache, llmStringKey, parsedOptions, handledOptions, runId }: {\n        prompts: string[];\n        cache: BaseCache<Generation[]>;\n        llmStringKey: string;\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        parsedOptions: any;\n        handledOptions: RunnableConfig;\n        runId?: string;\n    }): Promise<LLMResult & {\n        missingPromptIndices: number[];\n        startedRunManagers?: CallbackManagerForLLMRun[];\n    }>;\n    /**\n     * Run the LLM on the given prompts and input, handling caching.\n     */\n    generate(prompts: string[], options?: string[] | CallOptions, callbacks?: Callbacks): Promise<LLMResult>;\n    /**\n     * Get the identifying parameters of the LLM.\n     */\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    _identifyingParams(): Record<string, any>;\n    /**\n     * Return the string type key uniquely identifying this class of LLM.\n     */\n    abstract _llmType(): string;\n    _modelType(): string;\n}\n/**\n * LLM class that provides a simpler interface to subclass than {@link BaseLLM}.\n *\n * Requires only implementing a simpler {@link _call} method instead of {@link _generate}.\n *\n * @augments BaseLLM\n */\nexport declare abstract class LLM<CallOptions extends BaseLLMCallOptions = BaseLLMCallOptions> extends BaseLLM<CallOptions> {\n    /**\n     * Run the LLM on the given prompt and input.\n     */\n    abstract _call(prompt: string, options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<string>;\n    _generate(prompts: string[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<LLMResult>;\n}\n"],"mappings":";;;;;;;;KAMYa,aAAAA;;EAAAA,KAAAA,EAAAA,MAAAA;AAIZ,CAAA,GADIC,MACaC,CAAAA,MAAAA,EAAAA,GAAa,CAAA;AAEbC,UAFAD,aAAAA,SAAsBL,uBAEKF,CAAAA,CAK5C;AAAqC,UALpBQ,kBAAAA,SAA2BR,4BAKP,CAAA;;;;AAEkBG,uBAFzBM,OAEyBN,CAAAA,oBAFGK,kBAEHL,GAFwBK,kBAExBL,CAAAA,SAFoDJ,iBAEpDI,CAAAA,MAAAA,EAF8EO,WAE9EP,CAAAA,CAAAA;EAAc;EAArB,iBAAzBS,EAAAA,IAAAA,CAAKF,WAALE,EAAkBD,OAAlBC,CAAAA,MAAgCT,cAAhCS,EAAAA,QAAAA,GAAAA,SAAAA,GAAAA,gBAAAA,CAAAA,CAAAA;EAAI;EAWa,YAAYF,EAAAA,MAAAA,EAAAA;EAAW;;;;;;;;EAId,MAAYA,CAAAA,KAAAA,EAJ3CT,sBAI2CS,EAAAA,OAAAA,CAAAA,EAJTA,WAISA,CAAAA,EAJKG,OAILH,CAAAA,MAAAA,CAAAA;EAAW;EAAiB,qBASxDlB,CAAAA,MAAAA,EAAAA,MAAAA,EAAAA,QAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,WAAAA,CAAAA,EAX4DK,wBAW5DL,CAAAA,EAXuFsB,cAWvFtB,CAXsGG,eAWtGH,CAAAA;EAAwB,UAAyBkB,4CAAAA,CAAAA,OAAAA,CAAAA,EAVbK,OAUaL,CAVLA,WAUKA,CAAAA,CAAAA,EAAAA,CAVWP,cAUXO,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,CAAAA;EAAW,eAAcZ,CAAAA,KAAAA,EAThFG,sBASgFH,EAAAA,OAAAA,CAAAA,EAT9CY,WAS8CZ,CAAAA,EAThCgB,cASgChB,CAAAA,MAAAA,CAAAA;EAAS;;;;;;;;EAYC,cAAuBD,CAAAA,YAAAA,EAZ3GL,wBAY2GK,EAAAA,EAAAA,OAAAA,CAAAA,EAAAA,MAAAA,EAAAA,GAZ1Da,WAY0Db,EAAAA,SAAAA,CAAAA,EAZjCC,SAYiCD,CAAAA,EAZrBgB,OAYqBhB,CAZbJ,SAYaI,CAAAA;EAAwB;;;EACvI,SAAEoB,SAAAA,CAAAA,OAAAA,EAAAA,MAAAA,EAAAA,EAAAA,OAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,UAAAA,CAAAA,EAT4DpB,wBAS5DoB,CAAAA,EATuFJ,OASvFI,CAT+FxB,SAS/FwB,CAAAA;EAAK;;;EAA6C;EAAO,gBAE/DvB,CAAAA,QAAAA,CAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,CAAAA,EAAAA,GAAAA;EAAU,iBAApBU,CAAAA,SAAAA,EALkBX,SAKlBW,CAAAA,EAL8BX,SAK9BW,EAAAA;EAAS;EAIc,iBAEtBX,CAAAA,OAAAA,EAAAA,MAAAA,EAAAA,EAAAA,aAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,cAAAA,EATmFG,kBASnFH,EAAAA,kBAAAA,CAAAA,EAT4HI,wBAS5HJ,EAAAA,CAAAA,EATyJoB,OASzJpB,CATiKA,SASjKA,CAAAA;EAAS,eAEII,CAAAA;IAAAA,OAAAA;IAAAA,KAAAA;IAAAA,YAAAA;IAAAA,aAAAA;IAAAA,cAAAA;IAAAA;EAjD+F,CAiD/FA,EAAAA;IAFrBgB,OAAAA,EAAAA,MAAAA,EAAAA;IAO6CH,KAAAA,EAbtCN,SAasCM,CAb5BhB,UAa4BgB,EAAAA,CAAAA;IAAyBZ,YAAAA,EAAAA,MAAAA;IAAoBL;IAARoB,aAAAA,EAAAA,GAAAA;IAKhEP,cAAAA,EAdFH,cAcEG;IA3DiFP,KAAAA,CAAAA,EAAAA,MAAAA;EAAiB,CAAA,CAAA,EA+CpHc,OA/CoH,CA+C5GpB,SA/C4G,GAAA;IAyE9F6B,oBAAG,EAAA,MAAA,EAAA;IAAA,kBAAA,CAAA,EAxBJzB,wBAwBI,EAAA;EAAA,CAAA,CAAA;EAAuC;;;EAIoC,QAAGgB,CAAAA,OAAAA,EAAAA,MAAAA,EAAAA,EAAAA,OAAAA,CAAAA,EAAAA,MAAAA,EAAAA,GAvB1DH,WAuB0DG,EAAAA,SAAAA,CAAAA,EAvBjCf,SAuBiCe,CAAAA,EAvBrBA,OAuBqBA,CAvBbpB,SAuBaoB,CAAAA;EAAO;;;EACF;EALN,kBAAA,CAAA,CAAA,EAdpFP,MAcoF,CAAA,MAAA,EAAA,GAAA,CAAA;;;;;;;;;;;;;;uBAAhFgB,wBAAwBd,qBAAqBA,4BAA4BC,QAAQC;;;;kFAI3Bb,2BAA2BgB;gFAC7BhB,2BAA2BgB,QAAQpB"}