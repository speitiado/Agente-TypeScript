const require_rolldown_runtime = require('../_virtual/rolldown_runtime.cjs');
const require_misc = require('./misc.cjs');
const require_standard = require('./standard.cjs');
const __langchain_core_output_parsers_openai_tools = require_rolldown_runtime.__toESM(require("@langchain/core/output_parsers/openai_tools"));
const __langchain_core_messages = require_rolldown_runtime.__toESM(require("@langchain/core/messages"));

//#region src/utils/message_inputs.ts
const completionsApiContentBlockConverter = {
	providerName: "ChatOpenAI",
	fromStandardTextBlock(block) {
		return {
			type: "text",
			text: block.text
		};
	},
	fromStandardImageBlock(block) {
		if (block.source_type === "url") return {
			type: "image_url",
			image_url: {
				url: block.url,
				...block.metadata?.detail ? { detail: block.metadata.detail } : {}
			}
		};
		if (block.source_type === "base64") {
			const url = `data:${block.mime_type ?? ""};base64,${block.data}`;
			return {
				type: "image_url",
				image_url: {
					url,
					...block.metadata?.detail ? { detail: block.metadata.detail } : {}
				}
			};
		}
		throw new Error(`Image content blocks with source_type ${block.source_type} are not supported for ChatOpenAI`);
	},
	fromStandardAudioBlock(block) {
		if (block.source_type === "url") {
			const data = (0, __langchain_core_messages.parseBase64DataUrl)({ dataUrl: block.url });
			if (!data) throw new Error(`URL audio blocks with source_type ${block.source_type} must be formatted as a data URL for ChatOpenAI`);
			const rawMimeType = data.mime_type || block.mime_type || "";
			let mimeType;
			try {
				mimeType = (0, __langchain_core_messages.parseMimeType)(rawMimeType);
			} catch {
				throw new Error(`Audio blocks with source_type ${block.source_type} must have mime type of audio/wav or audio/mp3`);
			}
			if (mimeType.type !== "audio" || mimeType.subtype !== "wav" && mimeType.subtype !== "mp3") throw new Error(`Audio blocks with source_type ${block.source_type} must have mime type of audio/wav or audio/mp3`);
			return {
				type: "input_audio",
				input_audio: {
					format: mimeType.subtype,
					data: data.data
				}
			};
		}
		if (block.source_type === "base64") {
			let mimeType;
			try {
				mimeType = (0, __langchain_core_messages.parseMimeType)(block.mime_type ?? "");
			} catch {
				throw new Error(`Audio blocks with source_type ${block.source_type} must have mime type of audio/wav or audio/mp3`);
			}
			if (mimeType.type !== "audio" || mimeType.subtype !== "wav" && mimeType.subtype !== "mp3") throw new Error(`Audio blocks with source_type ${block.source_type} must have mime type of audio/wav or audio/mp3`);
			return {
				type: "input_audio",
				input_audio: {
					format: mimeType.subtype,
					data: block.data
				}
			};
		}
		throw new Error(`Audio content blocks with source_type ${block.source_type} are not supported for ChatOpenAI`);
	},
	fromStandardFileBlock(block) {
		if (block.source_type === "url") {
			const data = (0, __langchain_core_messages.parseBase64DataUrl)({ dataUrl: block.url });
			if (!data) throw new Error(`URL file blocks with source_type ${block.source_type} must be formatted as a data URL for ChatOpenAI`);
			return {
				type: "file",
				file: {
					file_data: block.url,
					...block.metadata?.filename || block.metadata?.name ? { filename: block.metadata?.filename || block.metadata?.name } : {}
				}
			};
		}
		if (block.source_type === "base64") return {
			type: "file",
			file: {
				file_data: `data:${block.mime_type ?? ""};base64,${block.data}`,
				...block.metadata?.filename || block.metadata?.name || block.metadata?.title ? { filename: block.metadata?.filename || block.metadata?.name || block.metadata?.title } : {}
			}
		};
		if (block.source_type === "id") return {
			type: "file",
			file: { file_id: block.id }
		};
		throw new Error(`File content blocks with source_type ${block.source_type} are not supported for ChatOpenAI`);
	}
};
function _convertMessagesToOpenAIParams(messages, model) {
	return messages.flatMap((message) => {
		if ("output_version" in message.response_metadata && message.response_metadata?.output_version === "v1") return require_standard._convertToCompletionsMessageFromV1(message);
		let role = require_misc.messageToOpenAIRole(message);
		if (role === "system" && require_misc.isReasoningModel(model)) role = "developer";
		const content = typeof message.content === "string" ? message.content : message.content.map((m) => {
			if ((0, __langchain_core_messages.isDataContentBlock)(m)) return (0, __langchain_core_messages.convertToProviderContentBlock)(m, completionsApiContentBlockConverter);
			return m;
		});
		const completionParam = {
			role,
			content
		};
		if (message.name != null) completionParam.name = message.name;
		if (message.additional_kwargs.function_call != null) {
			completionParam.function_call = message.additional_kwargs.function_call;
			completionParam.content = "";
		}
		if ((0, __langchain_core_messages.isAIMessage)(message) && !!message.tool_calls?.length) {
			completionParam.tool_calls = message.tool_calls.map(__langchain_core_output_parsers_openai_tools.convertLangChainToolCallToOpenAI);
			completionParam.content = "";
		} else {
			if (message.additional_kwargs.tool_calls != null) completionParam.tool_calls = message.additional_kwargs.tool_calls;
			if (message.tool_call_id != null) completionParam.tool_call_id = message.tool_call_id;
		}
		if (message.additional_kwargs.audio && typeof message.additional_kwargs.audio === "object" && "id" in message.additional_kwargs.audio) {
			const audioMessage = {
				role: "assistant",
				audio: { id: message.additional_kwargs.audio.id }
			};
			return [completionParam, audioMessage];
		}
		return completionParam;
	});
}

//#endregion
exports._convertMessagesToOpenAIParams = _convertMessagesToOpenAIParams;
exports.completionsApiContentBlockConverter = completionsApiContentBlockConverter;
//# sourceMappingURL=message_inputs.cjs.map