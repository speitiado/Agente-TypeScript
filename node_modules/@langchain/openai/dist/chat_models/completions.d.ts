import { BaseChatOpenAI, BaseChatOpenAICallOptions } from "./base.js";
import { OpenAI as OpenAI$1 } from "openai";
import * as _langchain_core_messages1 from "@langchain/core/messages";
import { AIMessageChunk, BaseMessage, ChatMessageChunk, FunctionMessageChunk, HumanMessageChunk, SystemMessageChunk, ToolMessageChunk } from "@langchain/core/messages";
import { ChatGenerationChunk, ChatResult } from "@langchain/core/outputs";
import { CallbackManagerForLLMRun } from "@langchain/core/callbacks/manager";

//#region src/chat_models/completions.d.ts
interface ChatOpenAICompletionsCallOptions extends BaseChatOpenAICallOptions {}
type ChatCompletionsInvocationParams = Omit<OpenAI$1.Chat.Completions.ChatCompletionCreateParams, "messages">;
/**
 * OpenAI Completions API implementation.
 * @internal
 */
declare class ChatOpenAICompletions<CallOptions extends ChatOpenAICompletionsCallOptions = ChatOpenAICompletionsCallOptions> extends BaseChatOpenAI<CallOptions> {
  /** @internal */
  invocationParams(options?: this["ParsedCallOptions"], extra?: {
    streaming?: boolean;
  }): ChatCompletionsInvocationParams;
  _generate(messages: BaseMessage[], options: this["ParsedCallOptions"], runManager?: CallbackManagerForLLMRun): Promise<ChatResult>;
  _streamResponseChunks(messages: BaseMessage[], options: this["ParsedCallOptions"], runManager?: CallbackManagerForLLMRun): AsyncGenerator<ChatGenerationChunk>;
  completionWithRetry(request: OpenAI$1.Chat.ChatCompletionCreateParamsStreaming, requestOptions?: OpenAI$1.RequestOptions): Promise<AsyncIterable<OpenAI$1.Chat.Completions.ChatCompletionChunk>>;
  completionWithRetry(request: OpenAI$1.Chat.ChatCompletionCreateParamsNonStreaming, requestOptions?: OpenAI$1.RequestOptions): Promise<OpenAI$1.Chat.Completions.ChatCompletion>;
  /** @internal */
  protected _convertCompletionsMessageToBaseMessage(message: OpenAI$1.Chat.Completions.ChatCompletionMessage, rawResponse: OpenAI$1.Chat.Completions.ChatCompletion): BaseMessage;
  /** @internal */
  protected _convertCompletionsDeltaToBaseMessageChunk(
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  delta: Record<string, any>, rawResponse: OpenAI$1.Chat.Completions.ChatCompletionChunk, defaultRole?: OpenAI$1.Chat.ChatCompletionRole): AIMessageChunk<_langchain_core_messages1.MessageStructure> | ChatMessageChunk<_langchain_core_messages1.MessageStructure> | FunctionMessageChunk<_langchain_core_messages1.MessageStructure> | HumanMessageChunk<_langchain_core_messages1.MessageStructure> | SystemMessageChunk<_langchain_core_messages1.MessageStructure> | ToolMessageChunk<_langchain_core_messages1.MessageStructure>;
}
//#endregion
export { ChatOpenAICompletions, ChatOpenAICompletionsCallOptions };
//# sourceMappingURL=completions.d.ts.map